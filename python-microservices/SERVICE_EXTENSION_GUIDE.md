# Service Extension Guide

HÆ°á»›ng dáº«n táº¡o microservice má»›i tá»« template

## ðŸ“‹ BÆ°á»›c 1: Clone Template

```bash
# Copy structure tá»« brick_production_service
cp -r services/brick_production_service services/your_service_name
```

## ðŸ“ BÆ°á»›c 2: Cáº­p nháº­t config.py

```python
# services/your_service_name/config.py

SERVICE_NAME = "your_service_name"
SENSOR_TYPE = "your_sensor_type"  # 'moisture', 'machine_monitoring', etc.
OUTPUT_TABLE = "your_domain_stats"

# ThÃªm config riÃªng cho service cá»§a báº¡n
YOUR_SPECIFIC_THRESHOLD = 100.0
```

## ðŸ—„ï¸ BÆ°á»›c 3: Táº¡o Database Model

ThÃªm model vÃ o `shared/models.py`:

```python
class YourDomainStat(Base):
    """Domain-specific table for your service"""
    __tablename__ = "your_domain_stats"
    
    id = Column(Integer, primary_key=True)
    device_id = Column(String(50), nullable=False, index=True)
    timestamp = Column(DateTime(timezone=True), nullable=False)
    
    # ThÃªm cÃ¡c fields riÃªng cho domain cá»§a báº¡n
    your_metric_1 = Column(Float)
    your_metric_2 = Column(Integer)
    # ...
```

Cháº¡y migration:

```bash
alembic revision --autogenerate -m "Add your_domain_stats table"
alembic upgrade head
```

## ðŸ“Š BÆ°á»›c 4: Äá»‹nh nghÄ©a Schemas

### Input Schema (`schemas/input_schema.py`):

```python
from pydantic import BaseModel, Field

class YourSensorData(BaseModel):
    """Schema cho JSONB data tá»« sensor cá»§a báº¡n"""
    value1: float = Field(..., description="First value")
    value2: int = Field(..., description="Second value")
    # ...
```

### Output Schema (`schemas/output_schema.py`):

```python
class YourStatOutput(BaseModel):
    """Schema cho káº¿t quáº£ xá»­ lÃ½"""
    device_id: str
    start_time: datetime
    end_time: datetime
    
    # Metrics riÃªng cá»§a báº¡n
    avg_value1: float
    max_value2: int
    # ...
```

## ðŸ”§ BÆ°á»›c 5: Implement Business Logic

### ETL Service (`service/etl_service.py`):

```python
class ETLService:
    def extract_measurements(self, raw_measurements):
        # Validate vÃ  extract data tá»« JSONB
        pass
    
    def transform_to_time_series(self, measurements):
        # Chuyá»ƒn Ä‘á»•i thÃ nh time series
        pass
    
    def calculate_your_specific_metrics(self, time_series):
        # TÃ­nh toÃ¡n metrics riÃªng
        pass
```

### KPI Calculator (`service/kpi_calculator.py`):

```python
class KPICalculator:
    def calculate_your_kpis(self, time_series):
        # TÃ­nh toÃ¡n KPIs cho domain cá»§a báº¡n
        return {
            'kpi1': value1,
            'kpi2': value2
        }
```

## ðŸ“ˆ BÆ°á»›c 6: Analytics (Optional)

### Time Series Analysis:

```python
from services.brick_production_service.analytics import TimeSeriesAnalyzer

analyzer = TimeSeriesAnalyzer(window_size_minutes=30)
rolling_avg = analyzer.rolling_average(time_series, field='your_field')
```

### Anomaly Detection:

```python
from services.brick_production_service.analytics import AnomalyDetector

detector = AnomalyDetector(threshold_std=2.5)
anomalies = detector.detect_statistical_anomalies(time_series)
```

## ðŸš€ BÆ°á»›c 7: Main Processor

Cáº­p nháº­t `main.py`:

```python
class YourServiceProcessor:
    def __init__(self):
        self.etl_service = ETLService()
        self.kpi_calculator = KPICalculator()
        # ...
    
    def process_device(self, device_id, start_time, end_time):
        # 1. Load measurements
        # 2. Transform data
        # 3. Calculate metrics
        # 4. Save results
        pass
```

## âœ… BÆ°á»›c 8: Testing

Táº¡o test file `tests/services/your_service_name/test_processor.py`:

```python
import pytest
from services.your_service_name.main import YourServiceProcessor

def test_process_device():
    processor = YourServiceProcessor()
    result = processor.process_device(
        device_id="TEST-01",
        start_time=datetime(2025, 11, 20, 0, 0),
        end_time=datetime(2025, 11, 20, 23, 59)
    )
    assert result is not None
```

## ðŸ“ Checklist

- [ ] Clone template structure
- [ ] Update SERVICE_NAME vÃ  config
- [ ] Táº¡o database model trong shared/models.py
- [ ] Cháº¡y Alembic migration
- [ ] Äá»‹nh nghÄ©a input/output schemas
- [ ] Implement ETL logic
- [ ] Implement KPI calculation
- [ ] (Optional) Add analytics
- [ ] Update main processor
- [ ] Viáº¿t tests
- [ ] Test vá»›i dá»¯ liá»‡u tháº­t
- [ ] Document API vÃ  usage

## ðŸŽ¯ Best Practices

1. **Separation of Concerns**: Má»—i layer cÃ³ trÃ¡ch nhiá»‡m riÃªng
   - Repository: Database access only
   - Service: Business logic
   - Analytics: Statistical analysis
   - Schemas: Validation

2. **Type Safety**: LuÃ´n sá»­ dá»¥ng type hints
   ```python
   def process_data(data: List[Dict[str, Any]]) -> Optional[Result]:
       pass
   ```

3. **Error Handling**: Log errors vÃ  raise exceptions rÃµ rÃ ng
   ```python
   try:
       result = process()
   except Exception as e:
       logger.error("Processing failed", error=str(e))
       raise
   ```

4. **Logging**: Sá»­ dá»¥ng structured logging
   ```python
   logger.info("Processing started", device_id=device_id, count=100)
   ```

5. **Validation**: Validate táº¥t cáº£ input vá»›i Pydantic
   ```python
   validated_data = YourSchema.model_validate(raw_data)
   ```

## ðŸ“š TÃ i liá»‡u tham kháº£o

- SQLAlchemy docs: https://docs.sqlalchemy.org/
- Pydantic docs: https://docs.pydantic.dev/
- Structlog docs: https://www.structlog.org/
